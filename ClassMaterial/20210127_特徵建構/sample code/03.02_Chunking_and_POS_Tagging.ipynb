{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first 10 reviews\n",
    "f = open('../yelp_dataset/yelp_academic_dataset_review.json')\n",
    "js = []\n",
    "for i in range(10):\n",
    "    js.append(json.loads(f.readline()))\n",
    "f.close()\n",
    "review_df = pd.DataFrame(js)\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tcathy fix\n",
    "#安裝spacy (用admin權限開啟Anaconda prompt)\n",
    "#conda install spacy\n",
    "#python -m spacy download en  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spacy: [Installation instructions for spacy](https://spacy.io/docs/usage/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "=========================== Info about model 'en' ===========================\u001b[0m\n",
      "\n",
      "lang             en                            \n",
      "name             core_web_sm                   \n",
      "license          MIT                           \n",
      "author           Explosion                     \n",
      "url              https://explosion.ai          \n",
      "email            contact@explosion.ai          \n",
      "description      English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.\n",
      "sources          [{'name': 'OntoNotes 5', 'url': 'https://catalog.ldc.upenn.edu/LDC2013T19', 'license': 'commercial (licensed by Explosion)'}]\n",
      "pipeline         ['tagger', 'parser', 'ner']   \n",
      "version          2.3.1                         \n",
      "spacy_version    >=2.3.0,<2.4.0                \n",
      "parent_package   spacy                         \n",
      "labels           {'tagger': ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'XX', '_SP', '``'], 'parser': ['ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'attr', 'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', 'csubjpass', 'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg', 'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis', 'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct', 'quantmod', 'relcl', 'xcomp'], 'ner': ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']}\n",
      "link             C:\\Users\\tcath\\.conda\\envs\\myStudy\\lib\\site-packages\\spacy\\data\\en\n",
      "source           C:\\Users\\tcath\\.conda\\envs\\myStudy\\Lib\\site-packages\\en_core_web_sm\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lang': 'en',\n",
       " 'name': 'core_web_sm',\n",
       " 'license': 'MIT',\n",
       " 'author': 'Explosion',\n",
       " 'url': 'https://explosion.ai',\n",
       " 'email': 'contact@explosion.ai',\n",
       " 'description': 'English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.',\n",
       " 'sources': [{'name': 'OntoNotes 5',\n",
       "   'url': 'https://catalog.ldc.upenn.edu/LDC2013T19',\n",
       "   'license': 'commercial (licensed by Explosion)'}],\n",
       " 'pipeline': ['tagger', 'parser', 'ner'],\n",
       " 'version': '2.3.1',\n",
       " 'spacy_version': '>=2.3.0,<2.4.0',\n",
       " 'parent_package': 'spacy',\n",
       " 'accuracy': {'las': 89.7572754092,\n",
       "  'uas': 91.6570115569,\n",
       "  'token_acc': 99.756964111,\n",
       "  'las_per_type': {'advmod': {'p': 85.6065101297,\n",
       "    'r': 84.9512113055,\n",
       "    'f': 85.2776018577},\n",
       "   'aux': {'p': 97.9464841319, 'r': 98.0772654442, 'f': 98.0118311613},\n",
       "   'nsubj': {'p': 95.530627567, 'r': 94.7522887555, 'f': 95.1398662913},\n",
       "   'root': {'p': 89.5162856958, 'r': 91.1692936754, 'f': 90.3352283866},\n",
       "   'compound': {'p': 90.4871122761, 'r': 92.2811316552, 'f': 91.3753170839},\n",
       "   'poss': {'p': 97.0346623923, 'r': 97.4838969404, 'f': 97.2587609198},\n",
       "   'case': {'p': 97.927972373, 'r': 99.3493493493, 'f': 98.6335403727},\n",
       "   'dobj': {'p': 92.4513496547, 'r': 93.8729981675, 'f': 93.1567503459},\n",
       "   'prep': {'p': 85.6642170718, 'r': 86.2427438631, 'f': 85.9525069954},\n",
       "   'pobj': {'p': 96.0694769711, 'r': 96.6428459243, 'f': 96.3553084873},\n",
       "   'relcl': {'p': 76.5768958186, 'r': 78.3538796229, 'f': 77.4551971326},\n",
       "   'det': {'p': 97.7105145232, 'r': 97.7901904024, 'f': 97.7503362269},\n",
       "   'amod': {'p': 91.5748754262, 'r': 90.4891480402, 'f': 91.0287743996},\n",
       "   'attr': {'p': 90.4294478528, 'r': 92.9772918419, 'f': 91.6856728177},\n",
       "   'cc': {'p': 83.8244137102, 'r': 83.3532647692, 'f': 83.5881753313},\n",
       "   'mark': {'p': 90.3421052632, 'r': 90.9644939057, 'f': 90.6522313177},\n",
       "   'nmod': {'p': 76.3772954925, 'r': 55.7586837294, 'f': 64.4593166608},\n",
       "   'conj': {'p': 76.8877867328, 'r': 78.0490874764, 'f': 77.4640849469},\n",
       "   'advcl': {'p': 68.9203354298, 'r': 66.2301687232, 'f': 67.548478233},\n",
       "   'pcomp': {'p': 85.2515506547, 'r': 86.6246498599, 'f': 85.9326154915},\n",
       "   'nummod': {'p': 93.1951089846, 'r': 88.5353535354, 'f': 90.8054908055},\n",
       "   'nsubjpass': {'p': 92.4265842349, 'r': 92.0, 'f': 92.2127987664},\n",
       "   'quantmod': {'p': 85.3463587922, 'r': 78.0666125102, 'f': 81.5443360204},\n",
       "   'auxpass': {'p': 94.7204968944, 'r': 97.2665148064, 'f': 95.9766239604},\n",
       "   'ccomp': {'p': 79.9260844194, 'r': 83.6863543788, 'f': 81.7630086559},\n",
       "   'npadvmod': {'p': 76.8636539204, 'r': 70.6927175844, 'f': 73.6491487787},\n",
       "   'appos': {'p': 70.0960219479, 'r': 66.5075921909, 'f': 68.2546749777},\n",
       "   'neg': {'p': 94.5082376435, 'r': 94.9824385349, 'f': 94.7447447447},\n",
       "   'xcomp': {'p': 88.2854100106, 'r': 89.2677674085, 'f': 88.7738711405},\n",
       "   'predet': {'p': 85.2459016393, 'r': 89.2703862661, 'f': 87.2117400419},\n",
       "   'acomp': {'p': 90.3553299492, 'r': 88.717716357, 'f': 89.529035208},\n",
       "   'acl': {'p': 75.6578947368, 'r': 69.012547736, 'f': 72.182596291},\n",
       "   'oprd': {'p': 81.0810810811, 'r': 71.6417910448, 'f': 76.0697305864},\n",
       "   'dative': {'p': 73.9659367397, 'r': 69.7247706422, 'f': 71.7827626919},\n",
       "   'agent': {'p': 88.5328836425, 'r': 94.0860215054, 'f': 91.2250217202},\n",
       "   'meta': {'p': 94.7368421053, 'r': 34.615384615400004, 'f': 50.7042253521},\n",
       "   'dep': {'p': 40.329218107, 'r': 15.9090909091, 'f': 22.8172293364},\n",
       "   'prt': {'p': 81.9166666667, 'r': 88.082437276, 'f': 84.8877374784},\n",
       "   'expl': {'p': 98.3014861996, 'r': 99.1434689507, 'f': 98.7206823028},\n",
       "   'parataxis': {'p': 63.9240506329, 'r': 43.8177874187, 'f': 51.9948519949},\n",
       "   'intj': {'p': 69.387755102, 'r': 59.7802197802, 'f': 64.2266824085},\n",
       "   'csubj': {'p': 70.5882352941, 'r': 71.0059171598, 'f': 70.796460177},\n",
       "   'preconj': {'p': 57.4468085106, 'r': 62.7906976744, 'f': 60.0},\n",
       "   'csubjpass': {'p': 44.4444444444, 'r': 66.6666666667, 'f': 53.3333333333}},\n",
       "  'tags_acc': 97.056555292,\n",
       "  'ents_f': 85.4306864065,\n",
       "  'ents_p': 85.7239322492,\n",
       "  'ents_r': 85.1394400045,\n",
       "  'ents_per_type': {'ORG': {'p': 83.3194096352,\n",
       "    'r': 82.8808864266,\n",
       "    'f': 83.0995695042},\n",
       "   'CARDINAL': {'p': 83.9554682384, 'r': 86.32996633, 'f': 85.1261620186},\n",
       "   'DATE': {'p': 84.6522781775, 'r': 86.1275705821, 'f': 85.3835521769},\n",
       "   'GPE': {'p': 92.5831202046, 'r': 90.2180685358, 'f': 91.3852950458},\n",
       "   'PERSON': {'p': 88.0239520958, 'r': 92.0908379013, 'f': 90.0114810563},\n",
       "   'MONEY': {'p': 92.9181929182, 'r': 91.4663461538, 'f': 92.1865536039},\n",
       "   'PRODUCT': {'p': 52.1276595745, 'r': 24.1379310345, 'f': 32.9966329966},\n",
       "   'TIME': {'p': 70.1886792453, 'r': 70.9923664122, 'f': 70.5882352941},\n",
       "   'PERCENT': {'p': 91.8566775244, 'r': 88.125, 'f': 89.95215311},\n",
       "   'WORK_OF_ART': {'p': 48.1481481481, 'r': 38.8059701493, 'f': 42.9752066116},\n",
       "   'QUANTITY': {'p': 78.1954887218, 'r': 65.4088050314, 'f': 71.2328767123},\n",
       "   'NORP': {'p': 88.682581786, 'r': 89.2348754448, 'f': 88.9578713969},\n",
       "   'LOC': {'p': 70.8154506438, 'r': 66.0, 'f': 68.3229813665},\n",
       "   'EVENT': {'p': 63.2911392405, 'r': 37.037037037, 'f': 46.7289719626},\n",
       "   'ORDINAL': {'p': 80.0, 'r': 83.9694656489, 'f': 81.9366852886},\n",
       "   'FAC': {'p': 34.8623853211, 'r': 46.9135802469, 'f': 40.0},\n",
       "   'LAW': {'p': 62.962962963, 'r': 56.6666666667, 'f': 59.649122807},\n",
       "   'LANGUAGE': {'p': 75.0, 'r': 65.2173913043, 'f': 69.7674418605}}},\n",
       " 'speed': {'cpu': 6107.3535050376, 'gpu': None, 'nwords': 291315},\n",
       " 'labels': {'tagger': ['$',\n",
       "   \"''\",\n",
       "   ',',\n",
       "   '-LRB-',\n",
       "   '-RRB-',\n",
       "   '.',\n",
       "   ':',\n",
       "   'ADD',\n",
       "   'AFX',\n",
       "   'CC',\n",
       "   'CD',\n",
       "   'DT',\n",
       "   'EX',\n",
       "   'FW',\n",
       "   'HYPH',\n",
       "   'IN',\n",
       "   'JJ',\n",
       "   'JJR',\n",
       "   'JJS',\n",
       "   'LS',\n",
       "   'MD',\n",
       "   'NFP',\n",
       "   'NN',\n",
       "   'NNP',\n",
       "   'NNPS',\n",
       "   'NNS',\n",
       "   'PDT',\n",
       "   'POS',\n",
       "   'PRP',\n",
       "   'PRP$',\n",
       "   'RB',\n",
       "   'RBR',\n",
       "   'RBS',\n",
       "   'RP',\n",
       "   'SYM',\n",
       "   'TO',\n",
       "   'UH',\n",
       "   'VB',\n",
       "   'VBD',\n",
       "   'VBG',\n",
       "   'VBN',\n",
       "   'VBP',\n",
       "   'VBZ',\n",
       "   'WDT',\n",
       "   'WP',\n",
       "   'WP$',\n",
       "   'WRB',\n",
       "   'XX',\n",
       "   '_SP',\n",
       "   '``'],\n",
       "  'parser': ['ROOT',\n",
       "   'acl',\n",
       "   'acomp',\n",
       "   'advcl',\n",
       "   'advmod',\n",
       "   'agent',\n",
       "   'amod',\n",
       "   'appos',\n",
       "   'attr',\n",
       "   'aux',\n",
       "   'auxpass',\n",
       "   'case',\n",
       "   'cc',\n",
       "   'ccomp',\n",
       "   'compound',\n",
       "   'conj',\n",
       "   'csubj',\n",
       "   'csubjpass',\n",
       "   'dative',\n",
       "   'dep',\n",
       "   'det',\n",
       "   'dobj',\n",
       "   'expl',\n",
       "   'intj',\n",
       "   'mark',\n",
       "   'meta',\n",
       "   'neg',\n",
       "   'nmod',\n",
       "   'npadvmod',\n",
       "   'nsubj',\n",
       "   'nsubjpass',\n",
       "   'nummod',\n",
       "   'oprd',\n",
       "   'parataxis',\n",
       "   'pcomp',\n",
       "   'pobj',\n",
       "   'poss',\n",
       "   'preconj',\n",
       "   'predet',\n",
       "   'prep',\n",
       "   'prt',\n",
       "   'punct',\n",
       "   'quantmod',\n",
       "   'relcl',\n",
       "   'xcomp'],\n",
       "  'ner': ['CARDINAL',\n",
       "   'DATE',\n",
       "   'EVENT',\n",
       "   'FAC',\n",
       "   'GPE',\n",
       "   'LANGUAGE',\n",
       "   'LAW',\n",
       "   'LOC',\n",
       "   'MONEY',\n",
       "   'NORP',\n",
       "   'ORDINAL',\n",
       "   'ORG',\n",
       "   'PERCENT',\n",
       "   'PERSON',\n",
       "   'PRODUCT',\n",
       "   'QUANTITY',\n",
       "   'TIME',\n",
       "   'WORK_OF_ART']},\n",
       " 'link': 'C:\\\\Users\\\\tcath\\\\.conda\\\\envs\\\\myStudy\\\\lib\\\\site-packages\\\\spacy\\\\data\\\\en',\n",
       " 'source': 'C:\\\\Users\\\\tcath\\\\.conda\\\\envs\\\\myStudy\\\\Lib\\\\site-packages\\\\en_core_web_sm'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model meta data\n",
    "spacy.info('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload the language model\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping it in a pandas dataframe\n",
    "doc_df = review_df['text'].apply(nlp)\n",
    "\n",
    "type(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oh happy day, finally have a Canes near my casa. Yes just as others are griping about the Drive thru is packed just like most of the other canes in the area but I like to go sit down to enjoy my chicken. The cashiers are pleasant and as far as food wise i have yet to receive any funky chicken. The clean up crew zips around the dining area constantly so it's usually well kept. My only gripe is the one fella with Red hair he makes the rounds while cleaning but no smile or personality a few nights ago he tossed the napkins i just put on the table to help go with my meal. After I was done he just reached for my tray no \"excuse me or are you done with that?\"  I realize he's trying to do his job quickly but a little table manners goes along way. That being said still like to grub here and glad that there's finally a Cane's close to me."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got VERB VBP\n",
      "a DET DT\n",
      "letter NOUN NN\n",
      "in ADP IN\n",
      "the DET DT\n",
      "mail NOUN NN\n",
      "last ADJ JJ\n",
      "week NOUN NN\n",
      "that ADJ WDT\n",
      "said VERB VBD\n",
      "Dr. PROPN NNP\n",
      "Goldberg PROPN NNP\n",
      "is VERB VBZ\n",
      "moving VERB VBG\n",
      "to ADP IN\n",
      "Arizona PROPN NNP\n",
      "to PART TO\n",
      "take VERB VB\n",
      "a DET DT\n",
      "new ADJ JJ\n",
      "position NOUN NN\n",
      "there ADV RB\n",
      "in ADP IN\n",
      "June PROPN NNP\n",
      ". PUNCT .\n",
      "  SPACE SP\n",
      "He PRON PRP\n",
      "will VERB MD\n",
      "be VERB VB\n",
      "missed VERB VBN\n",
      "very ADV RB\n",
      "much ADV RB\n",
      ". PUNCT .\n",
      " \n",
      "\n",
      " SPACE SP\n",
      "I PRON PRP\n",
      "think VERB VBP\n",
      "finding VERB VBG\n",
      "a DET DT\n",
      "new ADJ JJ\n",
      "doctor NOUN NN\n",
      "in ADP IN\n",
      "NYC PROPN NNP\n",
      "that ADP IN\n",
      "you PRON PRP\n",
      "actually ADV RB\n",
      "like INTJ UH\n",
      "might VERB MD\n",
      "almost ADV RB\n",
      "be VERB VB\n",
      "as ADV RB\n",
      "awful ADJ JJ\n",
      "as ADP IN\n",
      "trying VERB VBG\n",
      "to PART TO\n",
      "find VERB VB\n",
      "a DET DT\n",
      "date NOUN NN\n",
      "! PUNCT .\n"
     ]
    }
   ],
   "source": [
    "# spacy gives you both fine grained (.pos_) + coarse grained (.tag_) parts of speech    \n",
    "for doc in doc_df[4]:\n",
    "    print(doc.text, doc.pos_, doc.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a Canes, my casa, others, the Drive thru, the other canes, the area, I, my chicken, The cashiers, food, i, any funky chicken, The clean up crew zips, the dining area, it, My only gripe, the one fella, Red hair, he, the rounds, no smile, personality, he, the napkins, i, the table, my meal, I, he, my tray, me, you, I, he, his job, a little table manners, way, grub, a Cane, me]\n"
     ]
    }
   ],
   "source": [
    "# spaCy also does noun chunking for us\n",
    "print([chunk for chunk in doc_df[4].noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [Textblob](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安裝Textblob\n",
    "#pip install -U textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default tagger in TextBlob uses the PatternTagger, the same as [pattern](https://www.clips.uantwerpen.be/pattern), which is fine for our example. To use the NLTK tagger, we can specify the pos_tagger when we call TextBlob. More [here](http://textblob.readthedocs.io/en/dev/advanced_usage.html#advanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df = review_df['text'].apply(TextBlob)\n",
    "\n",
    "type(blob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob_df[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tcath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tcathy fix\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oh', 'UH'),\n",
       " ('happy', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('finally', 'RB'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('Canes', 'NNP'),\n",
       " ('near', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('casa', 'NN'),\n",
       " ('Yes', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('others', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('griping', 'VBG'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Drive', 'NNP'),\n",
       " ('thru', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('packed', 'VBN'),\n",
       " ('just', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('canes', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('area', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('like', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('sit', 'RB'),\n",
       " ('down', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('enjoy', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('chicken', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('cashiers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('pleasant', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('as', 'RB'),\n",
       " ('far', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('food', 'NN'),\n",
       " ('wise', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('have', 'VBP'),\n",
       " ('yet', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('receive', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('funky', 'JJ'),\n",
       " ('chicken', 'NN'),\n",
       " ('The', 'DT'),\n",
       " ('clean', 'JJ'),\n",
       " ('up', 'RP'),\n",
       " ('crew', 'JJ'),\n",
       " ('zips', 'NNS'),\n",
       " ('around', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dining', 'VBG'),\n",
       " ('area', 'NN'),\n",
       " ('constantly', 'RB'),\n",
       " ('so', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('usually', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('kept', 'VB'),\n",
       " ('My', 'PRP$'),\n",
       " ('only', 'JJ'),\n",
       " ('gripe', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('one', 'CD'),\n",
       " ('fella', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('Red', 'NNP'),\n",
       " ('hair', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('rounds', 'NNS'),\n",
       " ('while', 'IN'),\n",
       " ('cleaning', 'VBG'),\n",
       " ('but', 'CC'),\n",
       " ('no', 'DT'),\n",
       " ('smile', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('personality', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('nights', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('tossed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('napkins', 'NNS'),\n",
       " ('i', 'VB'),\n",
       " ('just', 'RB'),\n",
       " ('put', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('table', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('help', 'VB'),\n",
       " ('go', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('meal', 'NN'),\n",
       " ('After', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('done', 'VBN'),\n",
       " ('he', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('reached', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('tray', 'NN'),\n",
       " ('no', 'DT'),\n",
       " ('excuse', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('or', 'CC'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('done', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('I', 'PRP'),\n",
       " ('realize', 'VBP'),\n",
       " ('he', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('his', 'PRP$'),\n",
       " ('job', 'NN'),\n",
       " ('quickly', 'RB'),\n",
       " ('but', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('table', 'JJ'),\n",
       " ('manners', 'NNS'),\n",
       " ('goes', 'VBZ'),\n",
       " ('along', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('That', 'DT'),\n",
       " ('being', 'VBG'),\n",
       " ('said', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('grub', 'VB'),\n",
       " ('here', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('glad', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('there', 'EX'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('finally', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('Cane', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('close', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('me', 'PRP')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df[4].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\tcath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'happy day', 'canes', 'food wise i', 'funky chicken', 'crew zips', 'red hair', 'napkins i', 'table manners', 'cane']\n"
     ]
    }
   ],
   "source": [
    "# blobs in TextBlob also have noun phrase extraction\n",
    "\n",
    "print([np for np in blob_df[4].noun_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
