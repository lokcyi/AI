{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('PY379': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fd79c5f311e48de877911d8cf1d56e7b724990a605ba536e714d512526dbebf5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['DATA_DATE', 'IDX', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n       'REMAIN_LAYER_SEQ', 'PRIORITY', 'LOT_TYPE', 'WIP_QTY', 'WS_DATE',\n       'IS_MAIN_ROUTE', '0I', '1C', '1D', '1F', '1G', '1I', '1M', '1N', '1P',\n       '1T', '1U', '1V', '2D', '2E', '2F', '2I', '2M', '2N', '2P', '2T', '2U',\n       '2V', '3D', '3E', '3G', '3I', '3K', '3M', '3N', '3P', '3S', '3T', '3U',\n       '3V', '4D', '4E', '4I', '4M', '4N', '4T', '4U', '4V', '5D', '5E', '5I',\n       '5M', '5N', '5P', '5S', '6D', '6I', '6N', '6P', '7D', '7I', '8D', '8I',\n       '9D', 'DO', 'ES', 'GN', 'HR', 'LI', 'PO', 'PV', 'SP', 'SV', 'TM', 'TU',\n       'TV', 'UG', 'ACTUAL_WP_OUT', 'out', 'in', 'cytime', 'remainDT',\n       'WIPDT'],\n      dtype='object')\nIndex(['DATA_DATE', 'IDX', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n       'REMAIN_LAYER_SEQ', 'PRIORITY', 'LOT_TYPE', 'WIP_QTY', 'WS_DATE',\n       'IS_MAIN_ROUTE', '0I', '1C', '1D', '1F', '1G', '1I', '1M', '1N', '1P',\n       '1T', '1U', '1V', '2D', '2E', '2F', '2I', '2M', '2N', '2P', '2T', '2U',\n       '2V', '3D', '3E', '3G', '3I', '3K', '3M', '3N', '3P', '3S', '3T', '3U',\n       '3V', '4D', '4E', '4I', '4M', '4N', '4T', '4U', '4V', '5D', '5E', '5I',\n       '5M', '5N', '5P', '5S', '6D', '6I', '6N', '6P', '7D', '7I', '8D', '8I',\n       '9D', 'DO', 'ES', 'GN', 'HR', 'LI', 'PO', 'PV', 'SP', 'SV', 'TM', 'TU',\n       'TV', 'UG', 'ACTUAL_WP_OUT', 'out', 'in', 'cytime', 'remainDT',\n       'WIPDT'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "#import data_preparer\n",
    "train_df = pd.read_csv('./Training_Data.csv') # 800 筆\n",
    "test_df = pd.read_csv('./Testing_Data.csv') # 800 筆\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['DATA_DATE', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n       'REMAIN_LAYER_SEQ', 'PRIORITY', 'LOT_TYPE', 'WIP_QTY', 'WS_DATE',\n       'IS_MAIN_ROUTE', 'ACTUAL_WP_OUT', 'out', 'in', 'cytime', 'remainDT',\n       'WIPDT'],\n      dtype='object')\nIndex(['DATA_DATE', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n       'REMAIN_LAYER_SEQ', 'PRIORITY', 'LOT_TYPE', 'WIP_QTY', 'WS_DATE',\n       'IS_MAIN_ROUTE', 'ACTUAL_WP_OUT', 'out', 'in', 'cytime', 'remainDT',\n       'WIPDT'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(['IDX','0I', '1C', '1D', '1F', '1G', '1I', '1M', '1N', '1P',\n",
    "       '1T', '1U', '1V', '2D', '2E', '2F', '2I', '2M', '2N', '2P', '2T', '2U',\n",
    "       '2V', '3D', '3E', '3G', '3I', '3K', '3M', '3N', '3P', '3S', '3T', '3U',\n",
    "       '3V', '4D', '4E', '4I', '4M', '4N', '4T', '4U', '4V', '5D', '5E', '5I',\n",
    "       '5M', '5N', '5P', '5S', '6D', '6I', '6N', '6P', '7D', '7I', '8D', '8I',\n",
    "       '9D', 'DO', 'ES', 'GN', 'HR', 'LI', 'PO', 'PV', 'SP', 'SV', 'TM', 'TU',\n",
    "       'TV', 'UG'], axis=1)  \n",
    "print(train_df.columns)  \n",
    "test_df = test_df.drop(['IDX','0I', '1C', '1D', '1F', '1G', '1I', '1M', '1N', '1P',\n",
    "       '1T', '1U', '1V', '2D', '2E', '2F', '2I', '2M', '2N', '2P', '2T', '2U',\n",
    "       '2V', '3D', '3E', '3G', '3I', '3K', '3M', '3N', '3P', '3S', '3T', '3U',\n",
    "       '3V', '4D', '4E', '4I', '4M', '4N', '4T', '4U', '4V', '5D', '5E', '5I',\n",
    "       '5M', '5N', '5P', '5S', '6D', '6I', '6N', '6P', '7D', '7I', '8D', '8I',\n",
    "       '9D', 'DO', 'ES', 'GN', 'HR', 'LI', 'PO', 'PV', 'SP', 'SV', 'TM', 'TU',\n",
    "       'TV', 'UG'], axis=1)  \n",
    "print(test_df.columns)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(47983, 17)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 47983 entries, 0 to 47982\nData columns (total 17 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   DATA_DATE         47983 non-null  int64  \n 1   LOT_ID            47983 non-null  object \n 2   STATUS            47983 non-null  object \n 3   CHIPNAME          47983 non-null  object \n 4   LAYER             47983 non-null  object \n 5   REMAIN_LAYER_SEQ  47556 non-null  float64\n 6   PRIORITY          47983 non-null  int64  \n 7   LOT_TYPE          47983 non-null  object \n 8   WIP_QTY           47983 non-null  int64  \n 9   WS_DATE           47983 non-null  object \n 10  IS_MAIN_ROUTE     47982 non-null  float64\n 11  ACTUAL_WP_OUT     47983 non-null  object \n 12  out               47983 non-null  object \n 13  in                47983 non-null  object \n 14  cytime            47983 non-null  int64  \n 15  remainDT          47983 non-null  int64  \n 16  WIPDT             47983 non-null  object \ndtypes: float64(2), int64(5), object(10)\nmemory usage: 6.2+ MB\nNone\n(1015, 17)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1015 entries, 0 to 1014\nData columns (total 17 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   DATA_DATE         1015 non-null   int64  \n 1   LOT_ID            1015 non-null   object \n 2   STATUS            1015 non-null   object \n 3   CHIPNAME          1015 non-null   object \n 4   LAYER             1015 non-null   object \n 5   REMAIN_LAYER_SEQ  1005 non-null   float64\n 6   PRIORITY          1015 non-null   int64  \n 7   LOT_TYPE          1015 non-null   object \n 8   WIP_QTY           1015 non-null   int64  \n 9   WS_DATE           1015 non-null   object \n 10  IS_MAIN_ROUTE     1015 non-null   int64  \n 11  ACTUAL_WP_OUT     1015 non-null   object \n 12  out               1015 non-null   object \n 13  in                1015 non-null   object \n 14  cytime            1015 non-null   int64  \n 15  remainDT          1015 non-null   int64  \n 16  WIPDT             1015 non-null   int64  \ndtypes: float64(1), int64(7), object(9)\nmemory usage: 134.9+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.info())\n",
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Columns like  \n",
    "#Continuous Columns like  \n",
    "#Requirement : I need count of output date\n",
    "\n",
    "# print(pd.crosstab(train_df.out,columns='WIPDT',margins=True))\n",
    "# print(pd.crosstab(test_df.out,columns='WIPDT',margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirement: All Numerical columns basic statistics.\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirement: All Numerical columns basic statistics.\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "pairwise_analysis='off' #相關性和其他型別的資料關聯可能需要花費較長時間。如果超過了某個閾值，就需要設定這個引數為on或者off，以判斷是否需要分析資料相關性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_train = sv.analyze([train_df, 'train']) # 'train'是指會給這個資料集命名為train\n",
    "report_train.show_html(filepath='Basic_train_report.html') # 儲存為html的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = sv.FeatureConfig(skip=['DATA_DATE','ACTUAL_WP_OUT','WS_DATE'],  # 要忽略哪個特徵\n",
    "                                  force_cat=[ 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER','PRIORITY', 'LOT_TYPE',  'WS_DATE','IS_MAIN_ROUTE'], # Categorical特徵\n",
    "                                  force_num=['WIP_QTY','REMAIN_LAYER_SEQ'], # Numerical特徵\n",
    "                                  force_text=None) # Text特徵\n",
    "report_train_with_target = sv.analyze([train_df, 'train'],\n",
    "                                     target_feat='remainDT', # 加入特徵變數\n",
    "                                     feat_cfg=feature_config) \n",
    "report_train_with_target.show_html(filepath='Basic_train_report_with_target.html')                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compare_report = sv.compare([train_df, 'Training Data'], # 使用compare\n",
    "                            [test_df, 'Test Data'],\n",
    "                            'remainDT',\n",
    "                            feat_cfg=feature_config)\n",
    "\n",
    "compare_report.show_html(filepath='Compare_train_test_report.html')                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_subsets_report = sv.compare_intra(train_df,\n",
    "                                          train_df['LOT_TYPE']=='FDY', # 給條件區分\n",
    "                                          ['FDY', 'ENG'], # 為兩個子資料集命名 \n",
    "                                          target_feat='cytime',\n",
    "                                          feat_cfg=feature_config)\n",
    "\n",
    "compare_subsets_report.show_html(filepath='Compare_male_female_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.dropna(axis='REMAIN_LAYER_SEQ')\n",
    "print(test_df.shape)\n",
    "print(train_df.shape)\n",
    "#train_df1=test_df.dropna(axis='REMAIN_LAYER_SEQ')\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除null值\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "#train_df.dropna(axis='REMAIN_LAYER_SEQ')\n",
    "print(test_df.shape)\n",
    "print(train_df.shape)\n",
    "#train_df1=test_df.dropna(axis='REMAIN_LAYER_SEQ')\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 建立模型\n",
    "print(\"\\n[Info] 建立模型\")  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "  \n",
    "model = Sequential()  \n",
    "#Dense 意思是這個神經層是全連線層\n",
    "# 輸入層\n",
    "#model.add(Dense(units=3, input_dim=1, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=17, input_dim=9, kernel_initializer='random_uniform', activation='relu'))\n",
    "\n",
    "# 隱藏層\n",
    "#model.add(Dense(units=5, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=20, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dense(units=30, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dense(units=40, kernel_initializer='random_uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(units=150, kernel_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='zeros', activation='relu'))\n",
    "model.add(Dense(units=170, kernel_initializer='zeros', activation='relu'))\n",
    "\n",
    "# 輸出層\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "#print(\"\\n[Info] Show model summary...\")  \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 將特徵欄位進行標準化 \n",
    "    #print(\"\\n[Info] Normalized features...\")  \n",
    "from sklearn import preprocessing  \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# train_df = train_df.drop(['DATA_DATE','ACTUAL_WP_OUT','WS_DATE'], axis=1)  \n",
    "# print(train_df.columns)  \n",
    "# test_df = test_df.drop(['DATA_DATE','ACTUAL_WP_OUT','WS_DATE'], axis=1)  \n",
    "# print(test_df.columns) \n",
    "\n",
    "\n",
    "le=LabelEncoder()\n",
    "for col in train_df[['LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER','PRIORITY', 'LOT_TYPE',  'WS_DATE','IS_MAIN_ROUTE']]:\n",
    "    train_df[col]=le.fit_transform(train_df[col])\n",
    "    test_df[col]=le.fit_transform(test_df[col])\n",
    "print('OK')\n",
    "# minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))  \n",
    "# scaledFeatures = minmax_scale.fit_transform(train_features)  \n",
    "\n",
    "# rescaling 特徵縮放(0~1) 特徵最小/全距\n",
    "# FS_1= preprocessing.MinMaxScaler().fit(train_features)\n",
    "# result_minmax= FS_1.transform(train_features)\n",
    "\n",
    "#numeric_features = train_df.select_dtypes(include=['numeric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder()\n",
    "train_df_ohe=enc.fit_transform(train_df).toarray()\n",
    "pd.DataFrame(train_df_ohe)\n",
    "\n",
    "test_df_ohe=enc.fit_transform(test_df).toarray()\n",
    "pd.DataFrame(test_df_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行訓練\n",
    "\n",
    "# 將 dataframe 轉換為 array\n",
    "ndarray = train_df.values  \n",
    "# print(\"\\n[Info] Translate into ndarray(%s) with shape=%s\" % (ndarray.__class__, str(ndarray.shape)))  \n",
    "# print(\"\\n[Info] Show top 2 records:\\n%s\\n\" % (ndarray[:2]))  \n",
    "# print(\"\\n[Info] ndarray:\")\n",
    "print('ndarray=>',ndarray)\n",
    "\n",
    "# Separate labels with features  \n",
    "train_labels = ndarray[:,0]    # Labels are the values we want to predict\n",
    "train_features = ndarray[:,1:] # Remove the labels from the features\n",
    "print('==========')\n",
    "print(train_labels)\n",
    "print('==========')\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n[Info] 訓練中...\")  \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "#train_history = model.fit(x=train_features, y=train_labels, validation_split=0.1, epochs=10, batch_size=30, verbose=2)  \n",
    "train_history = model.fit(x=train_features, y=train_labels, validation_split=0.1, epochs=200, batch_size=30, verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}