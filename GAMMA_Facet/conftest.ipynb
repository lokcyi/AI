{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('PY379': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fd79c5f311e48de877911d8cf1d56e7b724990a605ba536e714d512526dbebf5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytest'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6f3d334faec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseCrossValidator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytest'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import logging\n",
    "import operator\n",
    "from typing import Any, List, Mapping, Optional, Sequence, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import BaseCrossValidator, KFold\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "from sklearndf import TransformerDF\n",
    "from sklearndf.pipeline import RegressorPipelineDF\n",
    "from sklearndf.regression import (\n",
    "    SVRDF,\n",
    "    AdaBoostRegressorDF,\n",
    "    DecisionTreeRegressorDF,\n",
    "    ExtraTreeRegressorDF,\n",
    "    LinearRegressionDF,\n",
    "    RandomForestRegressorDF,\n",
    ")\n",
    "from sklearndf.regression.extra import LGBMRegressorDF\n",
    "from sklearndf.transformation import (\n",
    "    ColumnTransformerDF,\n",
    "    OneHotEncoderDF,\n",
    "    SimpleImputerDF,\n",
    ")\n",
    "\n",
    "import facet\n",
    "from facet.crossfit import LearnerCrossfit\n",
    "from facet.data import Sample\n",
    "from facet.inspection import LearnerInspector, TreeExplainerFactory\n",
    "from facet.selection import LearnerEvaluation, LearnerGrid, LearnerRanker\n",
    "from facet.validation import BootstrapCV, StratifiedBootstrapCV\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# print the FACET logo\n",
    "print(facet.__logo__)\n",
    "\n",
    "# disable SHAP debugging messages\n",
    "logging.getLogger(\"shap\").setLevel(logging.WARNING)\n",
    "\n",
    "# configure pandas text output\n",
    "pd.set_option(\"display.width\", None)  # get display width from terminal\n",
    "pd.set_option(\"precision\", 3)  # 3 digits precision for easier readability\n",
    "\n",
    "K_FOLDS = 5\n",
    "N_BOOTSTRAPS = 30\n",
    "\n",
    "STEP_IMPUTE = \"impute\"\n",
    "STEP_ONE_HOT_ENCODE = \"one-hot-encode\"\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def boston_target() -> str:\n",
    "    return \"price\"\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def iris_target_name() -> str:\n",
    "    return \"species\"\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def n_jobs() -> int:\n",
    "    return -1\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def cv_kfold() -> KFold:\n",
    "    # define a CV\n",
    "    return KFold(n_splits=K_FOLDS)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def cv_bootstrap() -> BaseCrossValidator:\n",
    "    # define a CV\n",
    "    return BootstrapCV(n_splits=N_BOOTSTRAPS, random_state=42)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def cv_stratified_bootstrap() -> BaseCrossValidator:\n",
    "    # define a CV\n",
    "    return StratifiedBootstrapCV(n_splits=N_BOOTSTRAPS, random_state=42)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def regressor_grids(simple_preprocessor: TransformerDF) -> List[LearnerGrid]:\n",
    "    random_state = {\"random_state\": [42]}\n",
    "\n",
    "    return [\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=LGBMRegressorDF()\n",
    "            ),\n",
    "            learner_parameters={\n",
    "                \"max_depth\": [5, 10],\n",
    "                \"min_split_gain\": [0.1, 0.2],\n",
    "                \"num_leaves\": [50, 100, 200],\n",
    "                **random_state,\n",
    "            },\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=AdaBoostRegressorDF()\n",
    "            ),\n",
    "            learner_parameters={\"n_estimators\": [50, 80], **random_state},\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=RandomForestRegressorDF()\n",
    "            ),\n",
    "            learner_parameters={\"n_estimators\": [50, 80], **random_state},\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=DecisionTreeRegressorDF()\n",
    "            ),\n",
    "            learner_parameters={\n",
    "                \"max_depth\": [0.5, 1.0],\n",
    "                \"max_features\": [0.5, 1.0],\n",
    "                **random_state,\n",
    "            },\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=ExtraTreeRegressorDF()\n",
    "            ),\n",
    "            learner_parameters={\"max_depth\": [5, 10, 12], **random_state},\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=SVRDF()\n",
    "            ),\n",
    "            learner_parameters={\"gamma\": [0.5, 1], \"C\": [50, 100]},\n",
    "        ),\n",
    "        LearnerGrid(\n",
    "            pipeline=RegressorPipelineDF(\n",
    "                preprocessing=simple_preprocessor, regressor=LinearRegressionDF()\n",
    "            ),\n",
    "            learner_parameters={\"normalize\": [False, True]},\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def regressor_ranker(\n",
    "    cv_kfold: KFold,\n",
    "    regressor_grids: List[LearnerGrid[RegressorPipelineDF]],\n",
    "    sample: Sample,\n",
    "    n_jobs: int,\n",
    ") -> LearnerRanker[RegressorPipelineDF]:\n",
    "    return LearnerRanker(\n",
    "        grids=regressor_grids, cv=cv_kfold, scoring=\"r2\", n_jobs=n_jobs\n",
    "    ).fit(sample=sample)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def best_lgbm_crossfit(\n",
    "    regressor_ranker: LearnerRanker[RegressorPipelineDF],\n",
    "    cv_kfold: KFold,\n",
    "    sample: Sample,\n",
    "    n_jobs: int,\n",
    ") -> LearnerCrossfit[RegressorPipelineDF]:\n",
    "    # we get the best model_evaluation which is a LGBM - for the sake of test\n",
    "    # performance\n",
    "    best_lgbm_evaluation: LearnerEvaluation[RegressorPipelineDF] = [\n",
    "        evaluation\n",
    "        for evaluation in regressor_ranker.ranking_\n",
    "        if isinstance(evaluation.pipeline.regressor, LGBMRegressorDF)\n",
    "    ][0]\n",
    "\n",
    "    best_lgbm_regressor: RegressorPipelineDF = best_lgbm_evaluation.pipeline\n",
    "\n",
    "    return LearnerCrossfit(\n",
    "        pipeline=best_lgbm_regressor,\n",
    "        cv=cv_kfold,\n",
    "        shuffle_features=True,\n",
    "        random_state=42,\n",
    "        n_jobs=n_jobs,\n",
    "    ).fit(sample=sample)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def feature_names(best_lgbm_crossfit: LearnerCrossfit[RegressorPipelineDF]) -> Set[str]:\n",
    "    \"\"\"\n",
    "    all unique features across the models in the crossfit, after preprocessing\n",
    "    \"\"\"\n",
    "    return functools.reduce(\n",
    "        operator.or_,\n",
    "        (set(model.feature_names_out_) for model in best_lgbm_crossfit.models()),\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def regressor_inspector(\n",
    "    best_lgbm_crossfit: LearnerCrossfit[RegressorPipelineDF], n_jobs: int\n",
    ") -> LearnerInspector:\n",
    "    return LearnerInspector(\n",
    "        explainer_factory=TreeExplainerFactory(\n",
    "            feature_perturbation=\"tree_path_dependent\", use_background_dataset=True\n",
    "        ),\n",
    "        n_jobs=n_jobs,\n",
    "    ).fit(crossfit=best_lgbm_crossfit)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def simple_preprocessor(sample: Sample) -> TransformerDF:\n",
    "    features = sample.features\n",
    "\n",
    "    column_transforms = []\n",
    "\n",
    "    numeric_columns = features.select_dtypes(np.number).columns\n",
    "    if numeric_columns is not None and len(numeric_columns) > 0:\n",
    "        column_transforms.append(\n",
    "            (STEP_IMPUTE, SimpleImputerDF(strategy=\"median\"), numeric_columns)\n",
    "        )\n",
    "\n",
    "    category_columns = features.select_dtypes(object).columns\n",
    "    if category_columns is not None and len(category_columns) > 0:\n",
    "        column_transforms.append(\n",
    "            (\n",
    "                STEP_ONE_HOT_ENCODE,\n",
    "                OneHotEncoderDF(sparse=False, handle_unknown=\"ignore\"),\n",
    "                category_columns,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return ColumnTransformerDF(transformers=column_transforms)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def boston_df(boston_target: str) -> pd.DataFrame:\n",
    "    #  load sklearn test-data and convert to pd\n",
    "    boston: Bunch = datasets.load_boston()\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        data=np.c_[boston.data, boston.target],\n",
    "        columns=[*boston.feature_names, boston_target],\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def sample(boston_df: pd.DataFrame, boston_target: str) -> Sample:\n",
    "    return Sample(observations=boston_df.iloc[:100, :], target_name=boston_target)\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def iris_df(iris_target_name: str) -> pd.DataFrame:\n",
    "    #  load sklearn test-data and convert to pd\n",
    "    iris: Bunch = datasets.load_iris()\n",
    "\n",
    "    iris_df = pd.DataFrame(\n",
    "        data=np.c_[iris.data, iris.target],\n",
    "        columns=[*iris.feature_names, iris_target_name],\n",
    "    )\n",
    "\n",
    "    # replace target numericals with actual class labels\n",
    "    iris_df.loc[:, iris_target_name] = (\n",
    "        iris_df.loc[:, iris_target_name]\n",
    "        .astype(int)\n",
    "        .map(dict(enumerate(iris.target_names)))\n",
    "    )\n",
    "\n",
    "    return iris_df\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def iris_sample(iris_df: pd.DataFrame, iris_target_name: str) -> Sample:\n",
    "    # the iris dataset\n",
    "    return Sample(\n",
    "        observations=iris_df.assign(weight=2.0),\n",
    "        target_name=iris_target_name,\n",
    "        weight_name=\"weight\",\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def iris_sample_binary(iris_sample: Sample) -> Sample:\n",
    "    # the iris dataset, retaining only two categories so we can do binary classification\n",
    "    return iris_sample.subsample(\n",
    "        loc=iris_sample.target.isin([\"virginica\", \"versicolor\"])\n",
    "    )\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def iris_sample_binary_dual_target(\n",
    "    iris_sample_binary: Sample, iris_target_name\n",
    ") -> Sample:\n",
    "    # the iris dataset, retaining only two categories so we can do binary classification\n",
    "    target = pd.Series(\n",
    "        index=iris_sample_binary.index,\n",
    "        data=pd.Categorical(iris_sample_binary.target).codes,\n",
    "        name=iris_target_name,\n",
    "    )\n",
    "    iris_target_2 = f\"{iris_target_name}2\"\n",
    "    return Sample(\n",
    "        iris_sample_binary.features.join(target).join(target.rename(iris_target_2)),\n",
    "        target_name=[iris_sample_binary.target_name, iris_target_2],\n",
    "    )\n",
    "\n",
    "\n",
    "def check_ranking(\n",
    "    ranking: List[LearnerEvaluation],\n",
    "    expected_scores: Sequence[float],\n",
    "    expected_learners: Optional[Sequence[type]],\n",
    "    expected_parameters: Optional[Mapping[int, Mapping[str, Any]]],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Test helper to check rankings produced by learner rankers\n",
    "    :param ranking: a list of LearnerEvaluations\n",
    "    :param expected_scores: expected ranking scores, rounded to 3 decimal places\n",
    "    :param expected_learners: expected learner classes\n",
    "    :param expected_parameters: expected learner parameters\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if expected_learners is None:\n",
    "        expected_learners = [None] * len(ranking)\n",
    "\n",
    "    for rank, (learner_eval, score_expected, learner_expected) in enumerate(\n",
    "        zip(ranking, expected_scores, expected_learners)\n",
    "    ):\n",
    "        score_actual = round(learner_eval.ranking_score, 3)\n",
    "        assert score_actual == pytest.approx(score_expected, abs=0.1), (\n",
    "            f\"unexpected score for learner at rank #{rank + 1}: \"\n",
    "            f\"got {score_actual} but expected {score_expected}\"\n",
    "        )\n",
    "        if learner_expected is not None:\n",
    "            learner_actual = learner_eval.pipeline.final_estimator\n",
    "            assert type(learner_actual) == learner_expected, (\n",
    "                f\"unexpected class for learner at rank #{rank}: \"\n",
    "                f\"got {type(learner_actual)} but expected {learner_expected}\"\n",
    "            )\n",
    "\n",
    "    if expected_parameters is not None:\n",
    "        for rank, parameters_expected in expected_parameters.items():\n",
    "            parameters_actual = ranking[rank].parameters\n",
    "            assert parameters_actual == parameters_expected, (\n",
    "                f\"unexpected parameters for learner at rank #{rank}: \"\n",
    "                f\"got {parameters_actual} but expected {parameters_expected}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}