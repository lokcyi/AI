{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('PY379': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fd79c5f311e48de877911d8cf1d56e7b724990a605ba536e714d512526dbebf5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "#import data_preparer\n",
    "\n",
    "# df = pd.read_csv('D:/projects/ai/poc/homework/training_data_20210128.csv')\n",
    "# df_test = pd.read_csv('D:/projects/ai/poc/homework/testing_data_20210128.csv')\n",
    "\n",
    "# print(df.columns)\n",
    "# print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('D:/projects/ai/poc/homework/training_data_20210128.csv')\n",
    "# df=df.head(1000)\n",
    "#df = pd.read_excel(source_file_path)\n",
    "#df = pd.read_csv(source_file_path)\n",
    "df_train = df_train.loc[df_train['LOT_TYPE']=='FDY']\n",
    "df_train = df_train.loc[df_train['LAYER']!='XX']\n",
    "df_train['CHIPNAME'] = df_train['CHIPNAME'].str.strip()\n",
    "df_train = df_train.loc[df_train['CHIPNAME']=='CHIP266']           \n",
    "\n",
    "df_train['PRIORITY'] = df_train['PRIORITY'].astype(str)\n",
    "df_train['IS_MAIN_ROUTE'] = df_train['IS_MAIN_ROUTE'].astype(str)\n",
    "df_train['DATA_DATE'] = df_train['DATA_DATE'].astype(str)\n",
    "          \n",
    "df_train['DATA_DATE'] = pd.to_datetime(df_train['DATA_DATE'], infer_datetime_format=True)\n",
    "df_train['WS_DATE'] = pd.to_datetime(df_train['WS_DATE'], infer_datetime_format=True)\n",
    "df_train = df_train.assign(PROCESSED_DAYS = ((df_train['DATA_DATE'] -df_train['WS_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))\n",
    "df_train['ACTUAL_WP_OUT'] =pd.to_datetime(df_train['ACTUAL_WP_OUT'], infer_datetime_format=True)\n",
    "df_train = df_train.assign(REMAIN_DAYS=((df_train['ACTUAL_WP_OUT']-df_train['DATA_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))\n",
    "df_train = df_train.assign(CYCLE_TIME=((df_train['ACTUAL_WP_OUT']-df_train['WS_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(df, colname, bounds = [0, .75]):\n",
    "    s = df[colname]\n",
    "    q = s.quantile(bounds)\n",
    "    return df[~s.clip(*q).isin(q)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('D:/projects/ai/poc/homework/testing_data_20210128.csv')\n",
    "df_test = df_test.loc[df_test['LOT_TYPE']=='FDY']\n",
    "df_test = df_test.loc[df_test['LAYER']!='XX']\n",
    "df_test['CHIPNAME'] = df_test['CHIPNAME'].str.strip()\n",
    "df_test = df_test.loc[df_test['CHIPNAME']=='CHIP266']   \n",
    "     \n",
    "\n",
    "df_test['PRIORITY'] = df_test['PRIORITY'].astype(str)\n",
    "df_test['IS_MAIN_ROUTE'] = df_test['IS_MAIN_ROUTE'].astype(str)\n",
    "df_test['DATA_DATE'] = df_test['DATA_DATE'].astype(str) \n",
    "\n",
    "df_test['DATA_DATE'] = pd.to_datetime(df_test['DATA_DATE'], infer_datetime_format=True)\n",
    "\n",
    "df_test['WS_DATE'] = pd.to_datetime(df_test['WS_DATE'], infer_datetime_format=True)\n",
    "df_test = df_test.assign(PROCESSED_DAYS = ((df_test['DATA_DATE'] -df_test['WS_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))\n",
    "df_test['ACTUAL_WP_OUT'] =pd.to_datetime(df_test['ACTUAL_WP_OUT'], infer_datetime_format=True)\n",
    "df_test = df_test.assign(REMAIN_DAYS=((df_test['ACTUAL_WP_OUT']-df_test['DATA_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))\n",
    "df_test = df_test.assign(CYCLE_TIME=((df_test['ACTUAL_WP_OUT']-df_test['WS_DATE'])/pd.Timedelta(1, 'D')).fillna(0).astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train =iqr(df_train,'CYCLE_TIME',[0, .75])     \n",
    "# df_test =iqr(df_test,'CYCLE_TIME',[0, .75])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['DATA_DATE', 'IDX', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n",
       "       'REMAIN_LAYER_SEQ', 'OP_NO', 'REMAIN_OP_SEQ', 'PRIORITY',\n",
       "       ...\n",
       "       'UM', 'UT', 'WL', 'WS', 'WT', 'ZL', 'ACTUAL_WP_OUT', 'PROCESSED_DAYS',\n",
       "       'REMAIN_DAYS', 'CYCLE_TIME'],\n",
       "      dtype='object', length=263)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['DATA_DATE', 'IDX', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n       'REMAIN_LAYER_SEQ', 'OP_NO', 'REMAIN_OP_SEQ', 'PRIORITY', 'LOT_TYPE',\n       'WIP_QTY', 'WS_DATE', 'IS_MAIN_ROUTE', 'ACTUAL_WP_OUT',\n       'PROCESSED_DAYS', 'REMAIN_DAYS', 'CYCLE_TIME'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    " #df = df.drop(columns=['IDX','LOT_TYPE','WS_DATE','ACTUAL_WP_OUT','DATA_DATE','LAYER','LOT_ID'])\n",
    " df_train = df_train.drop(df_train.loc[:, '0E':'ZL'].columns, axis = 1) \n",
    "\n",
    " #df_test = df_test.drop(columns=['IDX','LOT_TYPE','WS_DATE','ACTUAL_WP_OUT','DATA_DATE','LAYER','LOT_ID'])\n",
    " df_test = df_test.drop(df_test.loc[:, '0E':'ZL'].columns, axis = 1) \n",
    "\n",
    "\n",
    "print(df_test.columns)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14061, 18)\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 14061 entries, 2242 to 222839\nData columns (total 18 columns):\n #   Column            Non-Null Count  Dtype         \n---  ------            --------------  -----         \n 0   DATA_DATE         14061 non-null  datetime64[ns]\n 1   IDX               14061 non-null  int64         \n 2   LOT_ID            14061 non-null  object        \n 3   STATUS            14061 non-null  object        \n 4   CHIPNAME          14061 non-null  object        \n 5   LAYER             14061 non-null  object        \n 6   REMAIN_LAYER_SEQ  14061 non-null  float64       \n 7   OP_NO             14061 non-null  object        \n 8   REMAIN_OP_SEQ     14061 non-null  float64       \n 9   PRIORITY          14061 non-null  object        \n 10  LOT_TYPE          14061 non-null  object        \n 11  WIP_QTY           14061 non-null  int64         \n 12  WS_DATE           14061 non-null  datetime64[ns]\n 13  IS_MAIN_ROUTE     14061 non-null  object        \n 14  ACTUAL_WP_OUT     14061 non-null  datetime64[ns]\n 15  PROCESSED_DAYS    14061 non-null  float64       \n 16  REMAIN_DAYS       14061 non-null  float64       \n 17  CYCLE_TIME        14061 non-null  float64       \ndtypes: datetime64[ns](3), float64(5), int64(2), object(8)\nmemory usage: 2.0+ MB\nNone\n(310, 18)\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 310 entries, 402 to 780\nData columns (total 18 columns):\n #   Column            Non-Null Count  Dtype         \n---  ------            --------------  -----         \n 0   DATA_DATE         310 non-null    datetime64[ns]\n 1   IDX               310 non-null    int64         \n 2   LOT_ID            310 non-null    object        \n 3   STATUS            310 non-null    object        \n 4   CHIPNAME          310 non-null    object        \n 5   LAYER             310 non-null    object        \n 6   REMAIN_LAYER_SEQ  310 non-null    float64       \n 7   OP_NO             310 non-null    object        \n 8   REMAIN_OP_SEQ     310 non-null    float64       \n 9   PRIORITY          310 non-null    object        \n 10  LOT_TYPE          310 non-null    object        \n 11  WIP_QTY           310 non-null    int64         \n 12  WS_DATE           310 non-null    datetime64[ns]\n 13  IS_MAIN_ROUTE     310 non-null    object        \n 14  ACTUAL_WP_OUT     310 non-null    datetime64[ns]\n 15  PROCESSED_DAYS    310 non-null    float64       \n 16  REMAIN_DAYS       310 non-null    float64       \n 17  CYCLE_TIME        310 non-null    float64       \ndtypes: datetime64[ns](3), float64(5), int64(2), object(8)\nmemory usage: 46.0+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train.info())\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Columns like  \n",
    "#Continuous Columns like  \n",
    "#Requirement : I need count of output date\n",
    "\n",
    "# print(pd.crosstab(train_df.out,columns='WIPDT',margins=True))\n",
    "# print(pd.crosstab(test_df.out,columns='WIPDT',margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 IDX  REMAIN_LAYER_SEQ  REMAIN_OP_SEQ       WIP_QTY  \\\n",
       "count   14061.000000      14061.000000   14061.000000  14061.000000   \n",
       "mean   244141.061304         13.032786     275.512055     24.907261   \n",
       "std    145281.420496          8.351608     161.047537      0.957752   \n",
       "min      8864.000000          1.000000       0.000000      1.000000   \n",
       "25%    120446.000000          6.000000     133.000000     25.000000   \n",
       "50%    240504.000000         12.000000     280.000000     25.000000   \n",
       "75%    364395.000000         21.000000     421.000000     25.000000   \n",
       "max    503577.000000         27.000000     533.000000     25.000000   \n",
       "\n",
       "       PROCESSED_DAYS   REMAIN_DAYS    CYCLE_TIME  \n",
       "count    14061.000000  14061.000000  14061.000000  \n",
       "mean        30.268925     30.432173     60.701098  \n",
       "std         17.770886     17.861721      4.839966  \n",
       "min          0.154167      0.005556     34.490278  \n",
       "25%         15.221528     14.512500     58.429167  \n",
       "50%         29.272917     31.010417     60.750694  \n",
       "75%         45.255556     45.722917     63.334722  \n",
       "max         78.269444     74.098611    138.350694  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IDX</th>\n      <th>REMAIN_LAYER_SEQ</th>\n      <th>REMAIN_OP_SEQ</th>\n      <th>WIP_QTY</th>\n      <th>PROCESSED_DAYS</th>\n      <th>REMAIN_DAYS</th>\n      <th>CYCLE_TIME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n      <td>14061.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>244141.061304</td>\n      <td>13.032786</td>\n      <td>275.512055</td>\n      <td>24.907261</td>\n      <td>30.268925</td>\n      <td>30.432173</td>\n      <td>60.701098</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>145281.420496</td>\n      <td>8.351608</td>\n      <td>161.047537</td>\n      <td>0.957752</td>\n      <td>17.770886</td>\n      <td>17.861721</td>\n      <td>4.839966</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>8864.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.154167</td>\n      <td>0.005556</td>\n      <td>34.490278</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>120446.000000</td>\n      <td>6.000000</td>\n      <td>133.000000</td>\n      <td>25.000000</td>\n      <td>15.221528</td>\n      <td>14.512500</td>\n      <td>58.429167</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>240504.000000</td>\n      <td>12.000000</td>\n      <td>280.000000</td>\n      <td>25.000000</td>\n      <td>29.272917</td>\n      <td>31.010417</td>\n      <td>60.750694</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>364395.000000</td>\n      <td>21.000000</td>\n      <td>421.000000</td>\n      <td>25.000000</td>\n      <td>45.255556</td>\n      <td>45.722917</td>\n      <td>63.334722</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>503577.000000</td>\n      <td>27.000000</td>\n      <td>533.000000</td>\n      <td>25.000000</td>\n      <td>78.269444</td>\n      <td>74.098611</td>\n      <td>138.350694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "#Requirement: All Numerical columns basic statistics.\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 IDX  REMAIN_LAYER_SEQ  REMAIN_OP_SEQ     WIP_QTY  \\\n",
       "count     310.000000        310.000000     310.000000  310.000000   \n",
       "mean   536728.912903          7.238710     165.248387   24.703226   \n",
       "std       899.380471          4.748134     116.212058    2.230051   \n",
       "min    535018.000000          1.000000       2.000000    1.000000   \n",
       "25%    535974.500000          3.000000      57.000000   25.000000   \n",
       "50%    536670.000000          7.000000     160.000000   25.000000   \n",
       "75%    537520.750000         11.000000     272.000000   25.000000   \n",
       "max    539293.000000         24.000000     476.000000   25.000000   \n",
       "\n",
       "       PROCESSED_DAYS  REMAIN_DAYS  CYCLE_TIME  \n",
       "count      310.000000   310.000000  310.000000  \n",
       "mean        43.022079    17.235423   60.257502  \n",
       "std         12.151342    11.714860    4.419071  \n",
       "min          8.211806     0.078472   39.134722  \n",
       "25%         32.217535     7.252604   58.651563  \n",
       "50%         43.732292    15.133681   60.440278  \n",
       "75%         53.270660    28.712847   62.535937  \n",
       "max         66.272917    36.232639   72.343056  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IDX</th>\n      <th>REMAIN_LAYER_SEQ</th>\n      <th>REMAIN_OP_SEQ</th>\n      <th>WIP_QTY</th>\n      <th>PROCESSED_DAYS</th>\n      <th>REMAIN_DAYS</th>\n      <th>CYCLE_TIME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>310.000000</td>\n      <td>310.000000</td>\n      <td>310.000000</td>\n      <td>310.000000</td>\n      <td>310.000000</td>\n      <td>310.000000</td>\n      <td>310.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>536728.912903</td>\n      <td>7.238710</td>\n      <td>165.248387</td>\n      <td>24.703226</td>\n      <td>43.022079</td>\n      <td>17.235423</td>\n      <td>60.257502</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>899.380471</td>\n      <td>4.748134</td>\n      <td>116.212058</td>\n      <td>2.230051</td>\n      <td>12.151342</td>\n      <td>11.714860</td>\n      <td>4.419071</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>535018.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>8.211806</td>\n      <td>0.078472</td>\n      <td>39.134722</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>535974.500000</td>\n      <td>3.000000</td>\n      <td>57.000000</td>\n      <td>25.000000</td>\n      <td>32.217535</td>\n      <td>7.252604</td>\n      <td>58.651563</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>536670.000000</td>\n      <td>7.000000</td>\n      <td>160.000000</td>\n      <td>25.000000</td>\n      <td>43.732292</td>\n      <td>15.133681</td>\n      <td>60.440278</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>537520.750000</td>\n      <td>11.000000</td>\n      <td>272.000000</td>\n      <td>25.000000</td>\n      <td>53.270660</td>\n      <td>28.712847</td>\n      <td>62.535937</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>539293.000000</td>\n      <td>24.000000</td>\n      <td>476.000000</td>\n      <td>25.000000</td>\n      <td>66.272917</td>\n      <td>36.232639</td>\n      <td>72.343056</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "#Requirement: All Numerical columns basic statistics.\n",
    "df_test.describe()"
   ]
  },
  {
   "source": [
    "sweetviz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "pairwise_analysis='off' #相關性和其他型別的資料關聯可能需要花費較長時間。如果超過了某個閾值，就需要設定這個引數為on或者off，以判斷是否需要分析資料相關性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Done! Use 'show' commands to display/save.   |██████████| [100%]   00:00 -> (00:00 left)\n",
      "Report Basic_train_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "report_train = sv.analyze([df_train, 'train']) # 'train'是指會給這個資料集命名為train\n",
    "report_train.show_html(filepath='Basic_train_report.html') # 儲存為html的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Done! Use 'show' commands to display/save.   |██████████| [100%]   00:00 -> (00:00 left)Report Basic_train_report_with_target.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DATA_DATE', 'IDX', 'LOT_ID', 'STATUS', 'CHIPNAME', 'LAYER',\n",
    "# 'REMAIN_LAYER_SEQ', 'OP_NO', 'REMAIN_OP_SEQ', 'PRIORITY', 'LOT_TYPE',\n",
    "# 'WIP_QTY', 'WS_DATE', 'IS_MAIN_ROUTE', 'ACTUAL_WP_OUT',\n",
    "# 'PROCESSED_DAYS', 'REMAIN_DAYS'\n",
    "feature_config = sv.FeatureConfig(skip=['DATA_DATE','IDX','WS_DATE'],  # 要忽略哪個特徵\n",
    "                                  force_cat=[  'STATUS', 'CHIPNAME', 'LAYER','OP_NO','PRIORITY', 'LOT_TYPE',  'WS_DATE','IS_MAIN_ROUTE','ACTUAL_WP_OUT'], # Categorical特徵\n",
    "                                  force_num=['WIP_QTY','REMAIN_LAYER_SEQ','REMAIN_DAYS','PROCESSED_DAYS'], # Numerical特徵\n",
    "                                  force_text='LOT_ID') # Text特徵\n",
    "report_train_with_target = sv.analyze([df_train, 'train'],\n",
    "                                     target_feat='CYCLE_TIME', # 加入特徵變數\n",
    "                                     feat_cfg=feature_config) \n",
    "report_train_with_target.show_html(filepath='Basic_train_report_with_target.html')                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Done! Use 'show' commands to display/save.   |██████████| [100%]   00:02 -> (00:00 left)Report Compare_train_test_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compare_report = sv.compare([df_train, 'Training Data'], # 使用compare\n",
    "                            [df_test, 'Test Data'],\n",
    "                            'CYCLE_TIME',\n",
    "                            feat_cfg=feature_config)\n",
    "\n",
    "compare_report.show_html(filepath='Compare_train_test_report.html')    \n",
    "#\n",
    "# compare_report.show_notebook(  w=None, \n",
    "#                 h=None, \n",
    "#                 scale=None,\n",
    "#                 layout='widescreen',\n",
    "#                 filepath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                             |          | [  0%]   00:00 -> (? left)\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Summarizing dataframe]                      |          | [  0%]   00:00 -> (? left)\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-cd6dd3904cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'WAITING'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PROCESSING'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 為兩個子資料集命名\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                           \u001b[0mtarget_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'CYCLE_TIME'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                           feat_cfg=feature_config)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcompare_subsets_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Compare_male_female_report.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PY379\\lib\\site-packages\\sweetviz\\sv_public.py\u001b[0m in \u001b[0;36mcompare_intra\u001b[1;34m(source_df, condition_series, names, target_feat, feat_cfg, pairwise_analysis)\u001b[0m\n\u001b[0;32m     42\u001b[0m     report = sweetviz.DataframeReport([data_true, names[0]], target_feat,\n\u001b[0;32m     43\u001b[0m                                       \u001b[1;33m[\u001b[0m\u001b[0mdata_false\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                                       pairwise_analysis, feat_cfg)\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PY379\\lib\\site-packages\\sweetviz\\dataframe_report.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, source, target_feature_name, compare, pairwise_analysis, fc)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_description_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[Summarizing dataframe]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarize_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget_feature_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_columns\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_columns\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PY379\\lib\\site-packages\\sweetviz\\dataframe_report.py\u001b[0m in \u001b[0;36msummarize_dataframe\u001b[1;34m(self, source, name, target_dict, skip)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mtarget_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"memory_total\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mtarget_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"memory_single_row\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"memory_total\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtarget_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_rows\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mtarget_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"duplicates\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNumWithPercent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "compare_subsets_report = sv.compare_intra(df_train,\n",
    "                                          df_train['CYCLE_TIME']=='WAITING', # 給條件區分\n",
    "                                          ['WAITING', 'PROCESSING'], # 為兩個子資料集命名 \n",
    "                                          target_feat='CYCLE_TIME',\n",
    "                                          feat_cfg=feature_config)\n",
    "\n",
    "compare_subsets_report.show_html(filepath='Compare_male_female_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A=data.query(\"category in ('AAR', 'AAU')\")\n",
    "# B=data.query(\"category not in ('AAR', 'AAU')\")\n",
    "# sv.compare([A, 'A'], [B, 'B']).show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}